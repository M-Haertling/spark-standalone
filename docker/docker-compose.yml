version: "2"

services:
  spark-leader:
    build:
      context: .
      dockerfile: pyspark.Dockerfile
    image: pyspark
    container_name: spark-leader
    entrypoint: /leader.sh
    environment:
      SPARK_LEADER_PORT: 5800
      SPARK_LEADER_URL: spark-leader
      SPARK_LEADER_WEB_PORT: 8080
    ports:
      - "5900:8080"
    volumes:
      - "spark-leader:/spark"
    stdin_open: true
    tty: true
  spark-worker1:
    build:
      context: .
      dockerfile: pyspark.Dockerfile
    image: pyspark
    container_name: spark-worker1
    entrypoint: /worker.sh
    environment:
      SPARK_LEADER_PORT: 5800
      SPARK_LEADER_URL: spark-leader
      SPARK_WORKER_PORT: 5801
      SPARK_WORKER_URL: spark-worker1
      SPARK_WORKER_WEB_PORT: 8080
    ports:
      - "5901:8080"
    volumes:
      - "spark-follower:/spark"
    depends_on:
      - "spark-leader"
  spark-worker2:
    build:
      context: .
      dockerfile: pyspark.Dockerfile
    image: pyspark
    container_name: spark-worker2
    entrypoint: /worker.sh
    environment:
      SPARK_LEADER_PORT: 5800
      SPARK_LEADER_URL: spark-leader
      SPARK_WORKER_PORT: 5802
      SPARK_WORKER_URL: spark-worker2
      SPARK_WORKER_WEB_PORT: 8080
    ports:
      - "5902:8080"
    volumes:
      - "spark-follower:/spark"
    depends_on:
      - "spark-leader"
  database:
    image: mysql:latest
    restart: always
    container_name: database
    environment:
      MYSQL_ROOT_PASSWORD: example
    ports:
      - "3306:3306"
  adminer:
    image: adminer
    restart: always
    container_name: adminer
    ports:
      - 5903:8080
    stdin_open: true
    tty: true
  pyspark-client:
    build:
      context: .
      dockerfile: pyspark.Dockerfile
    image: pyspark
    container_name: pyspark-client
    entrypoint: sleep infinity
    volumes:
      - ../:/share:ro
volumes:
  spark-leader:
    driver: local
  spark-follower:
    driver: local